{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import arcpy\n",
    "import os\n",
    "import numpy\n",
    "import pandas\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.env.workspace = \"C:\\\\Users\\\\Jayant\\\\Desktop\\\\SSTD\\\\workspace\"\n",
    "print(arcpy.env.workspace)\n",
    "\n",
    "in_filename = \"C:\\\\Users\\\\Jayant\\\\Desktop\\\\SSTD\\\\outputs\\\\rti_joined_race_income_hhsize_features.csv\"\n",
    "def getCountyIoD(in_filename, level_of_aggregation):\n",
    "    rows = pandas.read_csv(filepath_or_buffer=os.path.join(arcpy.env.workspace, in_filename),\n",
    "                                 header=0,\n",
    "                                 index_col=False,\n",
    "                                 usecols=['sp_hh_id', 'hh_race', 'hh_size', 'GEOID20', \"COUNTYFP20\", \n",
    "                                          \"TRACTCE20\", \"GEOID20_1\"],\n",
    "                                 engine='c')\n",
    "    return rows\n",
    "    \n",
    "rows = getCountyIoD(in_filename, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update header, remove erroneous rows, update col. type and filter the dataset\n",
    "def preprocessing(rows, dropColumns):\n",
    "    # Rename headers\n",
    "    rows = rows.rename(columns={'GEOID20':'BLOCK_ID', 'GEOID20_1':'BLCKGRP_ID'})\n",
    "    rows = rows[rows['COUNTYFP20'] != ' '] # Remove rows with no county\n",
    "    rows['COUNTYFP20'] = rows['COUNTYFP20'].astype('int64') # Update column data type.\n",
    "    filter_data = rows.drop(columns=dropColumns) # Subsetting the data\n",
    "    print(filter_data.head()) # Print to check the results.\n",
    "    return filter_data\n",
    "\n",
    "# Function to group the dataset\n",
    "def grouping(filter_data, groupByArg):\n",
    "    grouped_df = filter_data.groupby(groupByArg).agg({'hh_race':list, 'hh_size':list}) # Group by \n",
    "    grouped_df = grouped_df.reset_index()\n",
    "    print(grouped_df.head())\n",
    "    return grouped_df\n",
    "    \n",
    "# tract_data = preprocessing(rows, ['BLOCK_ID', 'BLCKGRP_ID'])\n",
    "# grouped_tract_df = grouping(tract_data, ['COUNTYFP20','TRACTCE20'])\n",
    "\n",
    "# block_grp_data = preprocessing(rows, ['TRACTCE20', 'BLOCK_ID'])\n",
    "# grouped_bg_df = grouping(block_grp_data, ['COUNTYFP20','BLCKGRP_ID'])\n",
    "\n",
    "block_data = preprocessing(rows, ['TRACTCE20', 'BLCKGRP_ID'])\n",
    "grouped_block_df = grouping(block_data, ['COUNTYFP20','BLOCK_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create distribution for each county.\n",
    "def CreateDIST(grouped_df, agg_level):\n",
    "    data_store = {}\n",
    "    counties = grouped_df['COUNTYFP20'].unique()\n",
    "    test_flag = 1\n",
    "    for county_id in counties:\n",
    "        print(\"Currently processing county #{0}\".format(county_id))\n",
    "        tract_store = {}\n",
    "        county_data = grouped_df[grouped_df['COUNTYFP20'] == county_id] # Get the data for each county.\n",
    "  \n",
    "        for index, row in county_data.iterrows(): # Iterate over each tract.\n",
    "            #print(row)\n",
    "            tract_race_dist = {}\n",
    "            tract_id = row[agg_level] # <-- agg_level argument is here.\n",
    "            n_household = len(row['hh_race'])\n",
    "            if not (len('hh_race') == len('hh_size')):\n",
    "                print(\"Sanity check failed\")\n",
    "            print(\"There are {0} households in block #{1}\".format(n_household, tract_id))\n",
    "            list_race = row['hh_race']\n",
    "            list_size = row['hh_size']\n",
    "            for i in range(0, n_household): # Iterate over each household in every tract.\n",
    "                key = list_race[i] # Get the race of the current household.\n",
    "                if key in tract_race_dist:\n",
    "                    tract_race_dist[key] += int(list_size[i]) # Add the size of each household.\n",
    "                else:\n",
    "                    tract_race_dist[key] = int(list_size[i])\n",
    "            tract_store[tract_id] = tract_race_dist\n",
    "        data_store[county_id] = tract_store\n",
    "    return data_store\n",
    "#    if(test_flag == 1):\n",
    "#        break\n",
    "#data_store = CreateDIST(grouped_df, 'TRACTCE20')\n",
    "#block_grp_data_store = CreateDIST(grouped_bg_df, 'BLCKGRP_ID')\n",
    "block_data_store = CreateDIST(grouped_block_df, 'BLOCK_ID')\n",
    "print(\"Datastore created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data_store))\n",
    "print(len(block_grp_data_store))\n",
    "print(len(block_data_store))\n",
    "#keys = list(data_store.keys())\n",
    "print(data_store[1])\n",
    "print(block_grp_data_store[1])\n",
    "print(block_data_store[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCountyDIST(data_store):\n",
    "    racial_dist = {}\n",
    "    for County in data_store:\n",
    "        Tracts = data_store[County].keys()\n",
    "        dist = {}\n",
    "        for race in range(1, 10):\n",
    "            dist[race] = []\n",
    "    #    print(dist)\n",
    "        for Tract in Tracts: # Compute the racial distribution of counties grouped by census tracts.\n",
    "            for race in range(1, 10):\n",
    "                if race in data_store[County][Tract]:\n",
    "                    dist[race].append(data_store[County][Tract][race])\n",
    "                else:\n",
    "                    dist[race].append(0)\n",
    "        racial_dist[County] = dist\n",
    "    return racial_dist\n",
    "tract_racial_dist = createCountyDIST(data_store)\n",
    "print(tract_racial_dist[1])\n",
    "block_grp_racial_dist = createCountyDIST(block_grp_data_store)\n",
    "print(block_grp_racial_dist[1])\n",
    "block_racial_dist = createCountyDIST(block_data_store)\n",
    "print(block_racial_dist[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createStateDIST(tract_racial_dist):\n",
    "    county_racial_dist = {}\n",
    "    for race in range(1, 10):\n",
    "        county_racial_dist[race] = []\n",
    "    for county in tract_racial_dist.keys():\n",
    "        for race in range(1,10):\n",
    "            total = sum(tract_racial_dist[county][race])\n",
    "            county_racial_dist[race].append(total)\n",
    "    return county_racial_dist\n",
    "county_racial_dist = createStateDIST(tract_racial_dist)\n",
    "print(county_racial_dist)\n",
    "print(len(county_racial_dist[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMEI(Agg_DIST, Part_DIST, COUNTY_INDEX):\n",
    "    T = 0\n",
    "    for key in Agg_DIST.keys():\n",
    "        T += sum(Agg_DIST[key])\n",
    "    \n",
    "    N_Tracts = len(Part_DIST[1])\n",
    "    Ti = [0 for i in range(0, N_Tracts)]\n",
    "    for i in range(0, N_Tracts):\n",
    "        for key in Part_DIST.keys():\n",
    "            Ti[i] += Part_DIST[key][i]\n",
    "    \n",
    "    E = 0.0\n",
    "    for key in Agg_DIST.keys():\n",
    "        E += float(Agg_DIST[key][COUNTY_INDEX]) / sum(Agg_DIST[key])\n",
    "    \n",
    "    Ei = [0 for i in range(0, N_Tracts)]\n",
    "    for i in range(0, N_Tracts):\n",
    "        for key in Part_DIST.keys():\n",
    "#             print(Part_DIST[key])\n",
    "#             print(N_Tracts)\n",
    "#             print(Part_DIST[key][i])\n",
    "            Ei[i] += float(Part_DIST[key][i]) / (sum(Part_DIST[key]) + 0.0001)\n",
    "    \n",
    "    MEI = 0.0\n",
    "    for i in range(0, N_Tracts):\n",
    "        MEI += (float(Ti[i])/T) * ((E - Ei[i]) / E)\n",
    "    return MEI\n",
    "\n",
    "def countyMultivariateMEIRanker(Agg_DIST, racial_dist):\n",
    "    County_MEI = {}\n",
    "    county_index = 0\n",
    "    for key in racial_dist.keys():\n",
    "        #print(key)\n",
    "        MEI = computeMEI(Agg_DIST, racial_dist[key], county_index)\n",
    "        County_MEI[key] = MEI\n",
    "        county_index += 1\n",
    "    ranked_MEI = dict(sorted(County_MEI.items(), key=lambda item: item[1], reverse=True))\n",
    "    print(ranked_MEI)\n",
    "    return ranked_MEI\n",
    "#print(tract_racial_dist.keys())\n",
    "ranked_MEI = countyMultivariateMEIRanker(county_racial_dist, tract_racial_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Function to coumpute IOD for two different distributions.\n",
    "def computeIOD(l1, l2):\n",
    "    l1_sum = sum(l1)\n",
    "    l2_sum = sum(l2)\n",
    "    if (l1_sum == 0 or l2_sum == 0):\n",
    "        return 0.0\n",
    "    \n",
    "    norm_l1 = [float(i)/l1_sum for i in l1]\n",
    "    norm_l2 = [float(i)/l1_sum for i in l2]\n",
    "    \n",
    "    #print(\"l1={0} \\nl2={1} \\nl1-norm={2} \\nl2-norm={3}\".format(l1, l2, norm_l1, norm_l2))\n",
    "    \n",
    "    list_diff = [norm_l1[i] - norm_l2[i] for i in range(len(norm_l1))]\n",
    "    abs_sum = sum([abs(number) for number in list_diff])\n",
    "   # print(\"Index of Dissimilarity = {0}\".format(abs_sum/2))\n",
    "    return abs_sum / 2\n",
    "\n",
    "# Currently merging race 1 vs others.\n",
    "from operator import add\n",
    "def countyBivariateIODRanker(racial_dist):\n",
    "    # Compute IOD for each County\n",
    "    County_IOD = {} # Storing the Index of Dissimiliarity for a county.\n",
    "    for key in racial_dist:\n",
    "        init_list = racial_dist[key][2]\n",
    "        for i in range(3, 10):\n",
    "            init_list = list(map(add, init_list, racial_dist[key][i]))\n",
    "        IOD = computeIOD(racial_dist[key][1], init_list)\n",
    "        County_IOD[key] = IOD\n",
    "    ranked_County = dict(sorted(County_IOD.items(), key=lambda item: item[1], reverse=True))\n",
    "    print(ranked_County)\n",
    "    return ranked_County\n",
    "\n",
    "tract_ranked_County = countyBivariateIODRanker(tract_racial_dist)\n",
    "block_grp_ranked_County = countyBivariateIODRanker(block_grp_racial_dist)\n",
    "block_ranked_County = countyBivariateIODRanker(block_racial_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add names to county ids and provide a ranked (descending) list of counties.\n",
    "def countyNamedList(ranked_County):\n",
    "    #Create dataframe for IOD.\n",
    "    County_IOD = pandas.DataFrame(ranked_County.items(), columns = ['COUNTYFP20', 'IOD'])\n",
    "    # Index the df on COUNTY IDs.\n",
    "    County_IOD.set_index('COUNTYFP20')\n",
    "\n",
    "    # Read County shapefile.\n",
    "    arr = arcpy.da.TableToNumPyArray('tl_2020_27_county20.shp', ('COUNTYFP20', 'NAMELSAD20'))\n",
    "    # Create dataframe for county names.\n",
    "    County_Name = pandas.DataFrame(arr)\n",
    "    County_Name['COUNTYFP20'] = County_Name['COUNTYFP20'].astype('int64')\n",
    "    County_Name.set_index('COUNTYFP20')\n",
    "\n",
    "    # Create the ranked list for all the counties.\n",
    "    Ranked_List = County_Name.merge(County_IOD)\n",
    "\n",
    "    # Sort counties in descending order of their IOD.\n",
    "    Ranked_List = Ranked_List.sort_values(by = ['IOD'], ascending=False)\n",
    "    return Ranked_List\n",
    "tract_Ranked_List = countyNamedList(tract_ranked_County)\n",
    "block_grp_Ranked_List = countyNamedList(block_grp_ranked_County)\n",
    "block_Ranked_List = countyNamedList(block_ranked_County)\n",
    "tract_Ranked_MEI_List = countyNamedList(ranked_MEI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.set_option('display.max_rows', 10)\n",
    "print(tract_Ranked_List)\n",
    "print(block_grp_Ranked_List)\n",
    "print(block_Ranked_List)\n",
    "print(tract_Ranked_MEI_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Counties = list(tract_Ranked_List['NAMELSAD20'])\n",
    "Rankings = dict.fromkeys(Counties)\n",
    "for key in Rankings.keys():\n",
    "    Rankings[key] = [0,0,0]\n",
    "for i in range(0, len(tract_Ranked_List)):\n",
    "    tract_row = tract_Ranked_List.iloc[i]\n",
    "    block_grp_row = block_grp_Ranked_List.iloc[i]\n",
    "    block_row = block_Ranked_List.iloc[i]\n",
    "    \n",
    "    Rankings[tract_row['NAMELSAD20']][0] = i+1\n",
    "    Rankings[block_grp_row['NAMELSAD20']][1] = i+1\n",
    "    Rankings[block_row['NAMELSAD20']][2] = i+1\n",
    "#    print(\"{0} - {1} - {2}\".format(, block_grp_row['NAMELSAD20'], block_row['NAMELSAD20']))    \n",
    "for key in Rankings.keys():\n",
    "    print(\"{0}{1}\".format(key, Rankings[key]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
